{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatentSBERTa_claims_claims_results.json\n",
      "max of true scores 0.9976216554641724\n",
      "min of true scores 0.5284088850021362\n",
      "mean of true scores 0.8122842662315577\n",
      "recall_at_10 0.4568242814619627\n",
      "mean_rank 38.818186697896856\n",
      "mean_inv_rank 0.2833406867113786\n",
      "\n",
      "PatentSBERTa_TAC_TAC_results.json\n",
      "max of true scores 0.9922178387641907\n",
      "min of true scores 0.558128297328949\n",
      "mean of true scores 0.7966771529654112\n",
      "recall_at_10 0.5296857463524127\n",
      "mean_rank 31.680405504318557\n",
      "mean_inv_rank 0.32925121807953855\n",
      "\n",
      "PatentSBERTa_TAC_TA_results.json\n",
      "max of true scores 0.962474524974823\n",
      "min of true scores 0.3110102713108063\n",
      "mean of true scores 0.701722711480743\n",
      "recall_at_10 0.41974088713219143\n",
      "mean_rank 41.712323720294705\n",
      "mean_inv_rank 0.25527773410225746\n",
      "\n",
      "PatentSBERTa_claims_TA_results.json\n",
      "max of true scores 0.9638068675994873\n",
      "min of true scores 0.3343903720378876\n",
      "mean of true scores 0.6787789141456276\n",
      "recall_at_10 0.3230298150588005\n",
      "mean_rank 50.993417264431784\n",
      "mean_inv_rank 0.19029841408843873\n",
      "\n",
      "all-MiniLM-L6-v2_TA_TAC_results.json\n",
      "max of true scores 0.937678337097168\n",
      "min of true scores 0.00828113779425621\n",
      "mean of true scores 0.5653613841155497\n",
      "recall_at_10 0.5425706338749814\n",
      "mean_rank 29.726460254721147\n",
      "mean_inv_rank 0.33535785270212803\n",
      "\n",
      "all-MiniLM-L6-v2_TA_TA_results.json\n",
      "max of true scores 1.000000238418579\n",
      "min of true scores 0.0605427585542202\n",
      "mean of true scores 0.5782160494512969\n",
      "recall_at_10 0.5458888400917385\n",
      "mean_rank 29.58986239203632\n",
      "mean_inv_rank 0.34536818270141667\n",
      "\n",
      "PatentSBERTa_TA_claims_results.json\n",
      "max of true scores 0.9254652857780457\n",
      "min of true scores 0.3178865313529968\n",
      "mean of true scores 0.685389920108563\n",
      "recall_at_10 0.4672497926121113\n",
      "mean_rank 36.57661640560193\n",
      "mean_inv_rank 0.27881183130717996\n",
      "\n",
      "PatentSBERTa_TAC_claims_results.json\n",
      "max of true scores 0.9796620607376099\n",
      "min of true scores 0.5326939821243286\n",
      "mean of true scores 0.7920025276227805\n",
      "recall_at_10 0.5090055140779778\n",
      "mean_rank 33.58345044649392\n",
      "mean_inv_rank 0.3172389809505438\n",
      "\n",
      "all-MiniLM-L6-v2_TAC_TAC_results.json\n",
      "max of true scores 0.9884617924690247\n",
      "min of true scores 0.29959142208099365\n",
      "mean of true scores 0.6994610137930576\n",
      "recall_at_10 0.5560386473429952\n",
      "mean_rank 29.856821841604454\n",
      "mean_inv_rank 0.3431604057277344\n",
      "\n",
      "PatentSBERTa_TA_TA_results.json\n",
      "max of true scores 1.0000001192092896\n",
      "min of true scores 0.31471067667007446\n",
      "mean of true scores 0.7112175579130137\n",
      "recall_at_10 0.5248987459132388\n",
      "mean_rank 32.08656370467964\n",
      "mean_inv_rank 0.3288896839433828\n",
      "\n",
      "PatentSBERTa_claims_TAC_results.json\n",
      "max of true scores 0.9699565172195435\n",
      "min of true scores 0.5411014556884766\n",
      "mean of true scores 0.7908618897997226\n",
      "recall_at_10 0.43375542868296496\n",
      "mean_rank 40.441794759186074\n",
      "mean_inv_rank 0.2606604758509777\n",
      "\n",
      "all-MiniLM-L6-v2_claims_claims_results.json\n",
      "max of true scores 0.9970203638076782\n",
      "min of true scores 0.29081717133522034\n",
      "mean of true scores 0.6961783567313014\n",
      "recall_at_10 0.4951129654028205\n",
      "mean_rank 34.223227443517295\n",
      "mean_inv_rank 0.3101553119967671\n",
      "\n",
      "all-MiniLM-L6-v2_claims_TA_results.json\n",
      "max of true scores 0.9429839849472046\n",
      "min of true scores 0.06255453079938889\n",
      "mean of true scores 0.5432578370760548\n",
      "recall_at_10 0.4349777972966379\n",
      "mean_rank 39.59601083296736\n",
      "mean_inv_rank 0.2587321519507308\n",
      "\n",
      "PatentSBERTa_TA_TAC_results.json\n",
      "max of true scores 0.9550982117652893\n",
      "min of true scores 0.3544950485229492\n",
      "mean of true scores 0.7062615107347001\n",
      "recall_at_10 0.5180281071585419\n",
      "mean_rank 32.269511540526025\n",
      "mean_inv_rank 0.32193023312221325\n",
      "\n",
      "all-MiniLM-L6-v2_TAC_claims_results.json\n",
      "max of true scores 0.9719204306602478\n",
      "min of true scores 0.2773967683315277\n",
      "mean of true scores 0.6925765234861703\n",
      "recall_at_10 0.5236544185819548\n",
      "mean_rank 31.88659786268482\n",
      "mean_inv_rank 0.3252461890908155\n",
      "\n",
      "all-MiniLM-L6-v2_TAC_TA_results.json\n",
      "max of true scores 0.9460017085075378\n",
      "min of true scores 0.11642923206090927\n",
      "mean of true scores 0.5618993144041096\n",
      "recall_at_10 0.4791562972722395\n",
      "mean_rank 35.44410774410772\n",
      "mean_inv_rank 0.2962817519434113\n",
      "\n",
      "all-MiniLM-L6-v2_TA_claims_results.json\n",
      "max of true scores 0.9113754034042358\n",
      "min of true scores 0.028352854773402214\n",
      "mean of true scores 0.5473365544055194\n",
      "recall_at_10 0.4992753623188406\n",
      "mean_rank 33.34638657102426\n",
      "mean_inv_rank 0.3040898572917664\n",
      "\n",
      "all-MiniLM-L6-v2_claims_TAC_results.json\n",
      "max of true scores 0.9828404188156128\n",
      "min of true scores 0.28662535548210144\n",
      "mean of true scores 0.6930863920244639\n",
      "recall_at_10 0.5118601473673939\n",
      "mean_rank 33.15224710876888\n",
      "mean_inv_rank 0.3122449322896146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "results_dir = \"/Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/github/not_git/best_pipeline_search_results\"\n",
    "files = os.listdir(results_dir)\n",
    "\n",
    "for i in files:\n",
    "    print(i)\n",
    "    with open(os.path.join(results_dir, i)) as f:\n",
    "        results = json.load(f)\n",
    "    true_scores = []\n",
    "    for i in results[\"true_segments\"]:\n",
    "        true_scores += list(results[\"true_segments\"][i].values())\n",
    "    print(\"max of true scores\", np.max(true_scores))\n",
    "    print(\"min of true scores\", np.min(true_scores))\n",
    "    print(\"mean of true scores\", np.mean(true_scores))\n",
    "    print(\"recall_at_10\", results[\"recall_at_10\"])\n",
    "    print(\"mean_rank\", results[\"mean_rank\"])\n",
    "    print(\"mean_inv_rank\", results[\"mean_inv_rank\"])\n",
    "    print()\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
