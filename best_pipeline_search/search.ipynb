{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_models = [\"PatentSBERTa\", \"all-MiniLM-L6-v2\"]\n",
    "possible_data = [\"TA\", \"TAC\", \"claims\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "def mean_recall_at_k(true_labels, predicted_labels, k=10):\n",
    "    \"\"\"\n",
    "    Calculate the mean Recall@k for a list of recommendations.\n",
    "    \"\"\"\n",
    "    recalls_at_k = []\n",
    "\n",
    "    for true, pred in zip(true_labels, predicted_labels):\n",
    "        # Calculate Recall@k for each recommendation list\n",
    "        true_set = set(true)\n",
    "        k = min(k, len(pred))\n",
    "        relevant_count = sum(1 for item in pred[:k] if item in true_set)\n",
    "        recalls_at_k.append(relevant_count / len(true_set) if len(true_set) > 0 else 0)\n",
    "\n",
    "    # Calculate the mean Recall@k\n",
    "    mean_recall = sum(recalls_at_k) / len(recalls_at_k) if recalls_at_k else 0\n",
    "\n",
    "    return mean_recall\n",
    "\n",
    "def mean_inv_ranking(true_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    Calculate the mean of lists of the mean inverse rank of true relevant items\n",
    "    in the lists of sorted recommended items.\n",
    "    \"\"\"\n",
    "    mean_ranks = []\n",
    "\n",
    "    for true, pred in zip(true_labels, predicted_labels):\n",
    "        # Calculate the inverse rank of true relevant items\n",
    "        # in the recommendation list\n",
    "        ranks = []\n",
    "        for item in true:\n",
    "            try:\n",
    "                rank = 1 / (pred.index(item) + 1)\n",
    "            except ValueError:\n",
    "                rank = 0  # If item not found, assign 0\n",
    "            ranks.append(rank)\n",
    "\n",
    "        # Calculate the mean inverse rank of true relevant items\n",
    "        # in the recommendation list\n",
    "        mean_rank = sum(ranks) / len(ranks) if ranks else 0\n",
    "        mean_ranks.append(mean_rank)\n",
    "\n",
    "    # Calculate the mean of the mean inverse ranks across all recommendation lists\n",
    "    mean_of_mean_ranks = sum(mean_ranks) / len(mean_ranks) if mean_ranks else 0\n",
    "\n",
    "    return mean_of_mean_ranks\n",
    "\n",
    "def mean_ranking(true_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    Calculate the mean of lists of the mean rank of true relevant items\n",
    "    in the lists of sorted recommended items.\n",
    "    \"\"\"\n",
    "    mean_ranks = []\n",
    "\n",
    "    for true, pred in zip(true_labels, predicted_labels):\n",
    "        # Calculate the rank of true relevant items\n",
    "        # in the recommendation list\n",
    "        ranks = []\n",
    "        for item in true:\n",
    "            try:\n",
    "                rank = pred.index(item) + 1\n",
    "            except ValueError:\n",
    "                rank = len(pred)  # If item not found, assign the length of the list\n",
    "            ranks.append(rank)\n",
    "\n",
    "        # Calculate the mean rank of true relevant items\n",
    "        # in the recommendation list\n",
    "        mean_rank = sum(ranks) / len(ranks) if ranks else 0\n",
    "        mean_ranks.append(mean_rank)\n",
    "\n",
    "    # Calculate the mean of the mean ranks across all recommendation lists\n",
    "    mean_of_mean_ranks = sum(mean_ranks) / len(mean_ranks) if mean_ranks else 0\n",
    "\n",
    "    return mean_of_mean_ranks\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Put a citation mapping in a dict format\n",
    "    \"\"\"\n",
    "    # Initialize an empty dictionary to store the results\n",
    "    citing_to_cited_dict = {}\n",
    "\n",
    "    # Iterate over the items in the JSON list\n",
    "    for citation in citations:\n",
    "        # Check if the citing id already exists in the resulting dictionary\n",
    "        if citation[0] in citing_to_cited_dict:\n",
    "            # If the citing id exists, append the cited id to the existing list\n",
    "            citing_to_cited_dict[citation[0]].append(citation[2])\n",
    "        else:\n",
    "            # If the citing id doesn't exist, create a new list with the cited id for that citing id\n",
    "            citing_to_cited_dict[citation[0]] = [citation[2]]\n",
    "\n",
    "    return citing_to_cited_dict\n",
    "\n",
    "# for getting true labels and our predictions\n",
    "def get_true_and_predicted(citing_to_cited_dict, recommendations_dict):\n",
    "    \"\"\"\n",
    "    Get the true and predicted labels for the metrics calculation.\n",
    "    \"\"\"\n",
    "    # for i in recommendations_dict:\n",
    "    #     print(i, recommendations_dict[i])\n",
    "    #     break\n",
    "    \n",
    "    # Initialize lists to store true labels and predicted labels\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    not_in_citation_mapping = 0\n",
    "\n",
    "    # Iterate over the items in both dictionaries\n",
    "    for citing_id in recommendations_dict.keys():\n",
    "        # Check if the citing_id is present in both dictionaries\n",
    "        if citing_id in citing_to_cited_dict:\n",
    "            # If yes, append the recommended items from both dictionaries to the respective lists\n",
    "            true_labels.append(citing_to_cited_dict[citing_id])\n",
    "            predicted_labels.append(recommendations_dict[citing_id])\n",
    "        else:\n",
    "            print(citing_id, \"not in citation mapping\")\n",
    "            not_in_citation_mapping += 1\n",
    "\n",
    "    return true_labels, predicted_labels, not_in_citation_mapping\n",
    "\n",
    "# load embeddings\n",
    "def load_embeddings_and_ids(embedding_file, app_ids_file):\n",
    "    \"\"\"\n",
    "    Load the embeddings and application IDs from saved files\n",
    "    \"\"\"\n",
    "    print(f\"Loading embeddings from {embedding_file}\")\n",
    "    embeddings = torch.from_numpy(np.load(embedding_file))\n",
    "\n",
    "    print(f\"Loading app_ids from {app_ids_file}\")\n",
    "    with open(app_ids_file, 'r') as f:\n",
    "        app_ids = json.load(f)\n",
    "\n",
    "    print(f\"Loaded {len(embeddings)} embeddings and {len(app_ids)} app_ids\")\n",
    "    return embeddings, app_ids\n",
    "\n",
    "# calculating cosine similarity:\n",
    "def cos_sim(a, b):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
    "    :return: Matrix with res[i][j] = cos_sim(a[i], b[j])\n",
    "    \"\"\"\n",
    "    if not isinstance(a, torch.Tensor):\n",
    "        a = torch.tensor(a)\n",
    "\n",
    "    if not isinstance(b, torch.Tensor):\n",
    "        b = torch.tensor(b)\n",
    "\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n",
    "    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "\n",
    "def pytorch_cos_sim(a, b):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
    "    :return: Matrix with res[i][j] = cos_sim(a[i], b[j])\n",
    "    \"\"\"\n",
    "    return cos_sim(a, b)\n",
    "\n",
    "# for getting train alignments\n",
    "def citation_to_citing_to_cited_dict(citations):\n",
    "    \"\"\"\n",
    "    Put a citation mapping in a dict format\n",
    "    \"\"\"\n",
    "    # Initialize an empty dictionary to store the results\n",
    "    citing_to_cited_dict = {}\n",
    "\n",
    "    # Iterate over the items in the JSON list\n",
    "    for citation in citations:\n",
    "        # Check if the citing id already exists in the resulting dictionary\n",
    "        if citation[0] in citing_to_cited_dict:\n",
    "            # If the citing id exists, append the cited id to the existing list\n",
    "            citing_to_cited_dict[citation[0]].append(citation[2])\n",
    "        else:\n",
    "            # If the citing id doesn't exist, create a new list with the cited id for that citing id\n",
    "            citing_to_cited_dict[citation[0]] = [citation[2]]\n",
    "\n",
    "    return citing_to_cited_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e20da7a5b24cfdbb65a3c203af77ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6ab416f9b84a21b485cb61239867a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "incoming datatype:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc12c32b2d464f1bbd3f8633279c114b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "existing datatype:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_PatentSBERTa_mean_TA.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_PatentSBERTa_mean_TA.json\n",
      "Loaded 16837 embeddings and 16837 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_PatentSBERTa_mean_TA.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_PatentSBERTa_mean_TA.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d2936cc178454b81852ef26b26bc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_PatentSBERTa_mean_TAC.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_PatentSBERTa_mean_TAC.json\n",
      "Loaded 16837 embeddings and 16837 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_PatentSBERTa_mean_TA.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_PatentSBERTa_mean_TA.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11d497d226349a1b36e71a00386381c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_PatentSBERTa_mean_claims.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_PatentSBERTa_mean_claims.json\n",
      "Loaded 16834 embeddings and 16834 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_PatentSBERTa_mean_TA.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_PatentSBERTa_mean_TA.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d454f1ec0c62464ba24c78ba6853d2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09def68c5584281bfcbe232dbe9fa12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "existing datatype:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_PatentSBERTa_mean_TA.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_PatentSBERTa_mean_TA.json\n",
      "Loaded 16837 embeddings and 16837 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_PatentSBERTa_mean_TAC.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_PatentSBERTa_mean_TAC.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e912da1a026f4506984e7bfddba2dd14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_PatentSBERTa_mean_TAC.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_PatentSBERTa_mean_TAC.json\n",
      "Loaded 16837 embeddings and 16837 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_PatentSBERTa_mean_TAC.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_PatentSBERTa_mean_TAC.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632cc0226eec4615bf9ec87b8a5f6a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_PatentSBERTa_mean_claims.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_PatentSBERTa_mean_claims.json\n",
      "Loaded 16834 embeddings and 16834 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_PatentSBERTa_mean_TAC.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_PatentSBERTa_mean_TAC.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c6e66cc8e24d7a9e776bb5a552aeef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d51f11429e4b9983ee88af953e8c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "existing datatype:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_PatentSBERTa_mean_TA.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_PatentSBERTa_mean_TA.json\n",
      "Loaded 16837 embeddings and 16837 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_PatentSBERTa_mean_claims.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_PatentSBERTa_mean_claims.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d4dfa8fbc1427fad5370ed5f90d371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_PatentSBERTa_mean_TAC.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_PatentSBERTa_mean_TAC.json\n",
      "Loaded 16837 embeddings and 16837 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_PatentSBERTa_mean_claims.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_PatentSBERTa_mean_claims.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d013dc8db2124a8da82d35f640d90042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_PatentSBERTa_mean_claims.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_PatentSBERTa_mean_claims.json\n",
      "Loaded 16834 embeddings and 16834 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_PatentSBERTa_mean_claims.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_PatentSBERTa_mean_claims.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89bba202e484afb8b84a51c1dc02996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1157b04fbcbb4d969863ed294a47723a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "incoming datatype:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af88146b27b45af8605eccc2a3e31df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "existing datatype:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_TA.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_TA.json\n",
      "Loaded 16837 embeddings and 16837 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_all-MiniLM-L6-v2_mean_TA.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_all-MiniLM-L6-v2_mean_TA.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8690177878614c60aeb7f386126fd083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_TAC.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_TAC.json\n",
      "Loaded 16837 embeddings and 16837 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_all-MiniLM-L6-v2_mean_TA.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_all-MiniLM-L6-v2_mean_TA.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd09468a08fa46dbbff92bfeecdd44c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_claims.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_claims.json\n",
      "Loaded 16834 embeddings and 16834 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_all-MiniLM-L6-v2_mean_TA.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_all-MiniLM-L6-v2_mean_TA.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844b0ba047e7452eb885dc8b1657785d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5ad12fc4c64483b5cb762b12b9f95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "existing datatype:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_TA.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_TA.json\n",
      "Loaded 16837 embeddings and 16837 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_all-MiniLM-L6-v2_mean_TAC.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_all-MiniLM-L6-v2_mean_TAC.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401215954c5046f580f91b9abc87e0e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_TAC.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_TAC.json\n",
      "Loaded 16837 embeddings and 16837 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_all-MiniLM-L6-v2_mean_TAC.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_all-MiniLM-L6-v2_mean_TAC.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aad0f10ff874fb49fd32a6d35973dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_claims.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_claims.json\n",
      "Loaded 16834 embeddings and 16834 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_all-MiniLM-L6-v2_mean_TAC.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_all-MiniLM-L6-v2_mean_TAC.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ede1cedd5048de9804e06e572002c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0db97c41814228abd896b2b746e9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "existing datatype:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_TA.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_TA.json\n",
      "Loaded 16837 embeddings and 16837 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_all-MiniLM-L6-v2_mean_claims.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_all-MiniLM-L6-v2_mean_claims.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562c257cbc274221ae554e771d4b9268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_TAC.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_TAC.json\n",
      "Loaded 16837 embeddings and 16837 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_all-MiniLM-L6-v2_mean_claims.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_all-MiniLM-L6-v2_mean_claims.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7a146d62f841629a4ab53fd54e48a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/embeddings_all-MiniLM-L6-v2_mean_claims.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_docs/app_ids_all-MiniLM-L6-v2_mean_claims.json\n",
      "Loaded 16834 embeddings and 16834 app_ids\n",
      "Loading embeddings from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/embeddings_all-MiniLM-L6-v2_mean_claims.npy\n",
      "Loading app_ids from /Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025/embeddings/embeddings_precalculated_train/app_ids_all-MiniLM-L6-v2_mean_claims.json\n",
      "Loaded 6831 embeddings and 6831 app_ids\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498d8f5653b446f3a7e882ebd4a0ca7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cosine scores:   0%|          | 0/6831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TOP_N = 100\n",
    "K_VALUE = 10\n",
    "POOLING = \"mean\"                \n",
    "QUERY_SET = \"train\"  \n",
    "BASE_DIR = \"/Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/CodaBench/IR2025\"\n",
    "DOC_EMBEDDING_DIR = os.path.join(BASE_DIR, \"embeddings/embeddings_precalculated_docs\")\n",
    "TRAIN_EMBEDDING_DIR = os.path.join(BASE_DIR, \"embeddings/embeddings_precalculated_train\")\n",
    "TEST_EMBEDDING_DIR = os.path.join(BASE_DIR, \"embeddings/embeddings_precalculated_test\")\n",
    "OUTPUT_DIR = \"/Users/kshitij/Documents/UPSaclay/T4/InfoRetrieval/github/not_git/best_pipeline_search_results\"\n",
    "CITATION_FILE = os.path.join(BASE_DIR, \"Citation_JSONs/Citation_Train.json\")\n",
    "\n",
    "with open(CITATION_FILE, 'r') as f:\n",
    "    citations = json.load(f)\n",
    "citing_to_cited_dict = citation_to_citing_to_cited_dict(citations)\n",
    "\n",
    "for model in tqdm(possible_models, desc=\"model\"):\n",
    "    MODEL_NAME = model  \n",
    "\n",
    "    for incoming_patent_data in tqdm(possible_data, desc=\"incoming datatype\"):\n",
    "        CONTENT_TYPE_coming = incoming_patent_data\n",
    "\n",
    "        for existing_patent_data in tqdm(possible_data, desc=\"existing datatype\"):\n",
    "            CONTENT_TYPE_existing = existing_patent_data \n",
    "\n",
    "            DOC_EMBEDDING_FILE = os.path.join(DOC_EMBEDDING_DIR, f\"embeddings_{MODEL_NAME}_{POOLING}_{CONTENT_TYPE_existing}.npy\")\n",
    "            DOC_APP_IDS_FILE = os.path.join(DOC_EMBEDDING_DIR, f\"app_ids_{MODEL_NAME}_{POOLING}_{CONTENT_TYPE_existing}.json\")\n",
    "\n",
    "            QUERY_EMBEDDING_DIR = TRAIN_EMBEDDING_DIR if QUERY_SET == \"train\" else TEST_EMBEDDING_DIR\n",
    "            QUERY_EMBEDDING_FILE = os.path.join(QUERY_EMBEDDING_DIR, f\"embeddings_{MODEL_NAME}_{POOLING}_{CONTENT_TYPE_coming}.npy\")\n",
    "            QUERY_APP_IDS_FILE = os.path.join(QUERY_EMBEDDING_DIR, f\"app_ids_{MODEL_NAME}_{POOLING}_{CONTENT_TYPE_coming}.json\")\n",
    "\n",
    "            # Load existing embeddings and app_ids\n",
    "            doc_embeddings, doc_app_ids = load_embeddings_and_ids(DOC_EMBEDDING_FILE, DOC_APP_IDS_FILE)\n",
    "\n",
    "            # Load incoming embeddings and app_ids\n",
    "            query_embeddings, query_app_ids = load_embeddings_and_ids(QUERY_EMBEDDING_FILE, QUERY_APP_IDS_FILE)\n",
    "\n",
    "            app_id_to_index = {app_id: idx for idx, app_id in enumerate(doc_app_ids)}\n",
    "\n",
    "            only_query_results = {}\n",
    "            results = {}\n",
    "            results[\"segments\"] = {}\n",
    "            results[\"true_segments\"] = {}\n",
    "            \n",
    "            for i, (query_embedding, query_id) in enumerate(tqdm(zip(query_embeddings, query_app_ids), total=len(query_embeddings), desc=\"cosine scores\")):\n",
    "                # Compute cosine similarity\n",
    "                query_embedding = query_embedding.unsqueeze(0)\n",
    "                cos_scores = pytorch_cos_sim(query_embedding, doc_embeddings)[0].cpu()\n",
    "\n",
    "                # Sort results and get top N\n",
    "                top_n_index = torch.argsort(cos_scores, descending=True)[:TOP_N].numpy()\n",
    "\n",
    "                # Get application IDs of top N documents\n",
    "                top_n_app_ids = [doc_app_ids[i] for i in top_n_index]\n",
    "                top_n_scores = cos_scores[top_n_index].tolist()\n",
    "                \n",
    "                #results[query_id][0] = IDS\n",
    "                #results[query_id][0] = scores \n",
    "                only_query_results[query_id] = top_n_app_ids\n",
    "\n",
    "                results[\"segments\"][query_id] = dict(zip(top_n_app_ids, top_n_scores))\n",
    "                \n",
    "                results[\"true_segments\"][query_id] = {}\n",
    "                true_ids = citing_to_cited_dict.get(query_id, [])\n",
    "                \n",
    "                results[\"true_segments\"][query_id] = {\n",
    "                true_id: cos_scores[app_id_to_index[true_id]].item()\n",
    "                for true_id in true_ids\n",
    "            }\n",
    "\n",
    "            true_labels, predicted_labels, not_in_citation_mapping = get_true_and_predicted(citing_to_cited_dict, only_query_results)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            recall_at_k = mean_recall_at_k(true_labels, predicted_labels, k=K_VALUE)\n",
    "            results[f\"recall_at_{K_VALUE}\"] = recall_at_k\n",
    "\n",
    "            mean_rank = mean_ranking(true_labels, predicted_labels)\n",
    "            results[\"mean_rank\"] = mean_rank\n",
    "\n",
    "            mean_inv_rank = mean_inv_ranking(true_labels, predicted_labels)\n",
    "            results[\"mean_inv_rank\"] = mean_inv_rank\n",
    "\n",
    "            with open(os.path.join(OUTPUT_DIR,f\"{model}_{incoming_patent_data}_{existing_patent_data}_results.json\"), 'w') as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
